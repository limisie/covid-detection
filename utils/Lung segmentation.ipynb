{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3066216",
   "metadata": {},
   "source": [
    "# Lung segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9dba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from skimage import io, transform, exposure, color, morphology, measure, img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72163c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "MODEL_PATH = './uVAE.pt'\n",
    "HIDDEN = 16\n",
    "LATENT = 8\n",
    "PADDING = 32\n",
    "POST_PROCESS = True\n",
    "PREDICTIONS_DIR = '../data/segmented/'\n",
    "MASKS_DIR = '../data/masks/'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547385ec",
   "metadata": {},
   "source": [
    "## lungVAE implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2451aa1",
   "metadata": {},
   "source": [
    "To segment lungs, model introduced in [*Lung Segmentation from Chest X-rays using Variational Data Imputation*](https://arxiv.org/abs/2005.10052) by Raghavendra Selvan et al.\n",
    "\n",
    "The full implementation is available [here](https://github.com/raghavian/lungVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd79d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uVAE(nn.Module):\n",
    "    def __init__(self, nlatent, unet=False,\n",
    "                 nhid=8, ker=3, inCh=1, h=640, w=512):\n",
    "        super(uVAE, self).__init__()\n",
    "        self.latent_space = nlatent\n",
    "        self.unet = unet\n",
    "\n",
    "        if not self.unet:\n",
    "            self.enc11 = nn.Conv2d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "            self.enc12 = nn.Conv2d(nhid, nhid, kernel_size=ker, padding=1)\n",
    "\n",
    "            self.enc2 = self.convBlock(nhid, 2 * nhid, 2 * nhid, pool=True)\n",
    "            self.enc3 = self.convBlock(2 * nhid, 4 * nhid, 4 * nhid, pool=True)\n",
    "            self.enc4 = self.convBlock(4 * nhid, 8 * nhid, 8 * nhid, pool=True)\n",
    "            self.enc5 = self.convBlock(8 * nhid, 16 * nhid, 16 * nhid, pool=True)\n",
    "\n",
    "            self.bot11 = nn.Conv1d(16 * nhid, 1, kernel_size=1)\n",
    "            self.bot12 = nn.Conv1d(int((h / 16) * (w / 16)), 2 * nlatent, kernel_size=1)\n",
    "\n",
    "            self.bot21 = nn.Conv1d(nlatent, int((h / 64) * (w / 64)), kernel_size=1)\n",
    "            self.bot22 = nn.Conv1d(1, nhid, kernel_size=1)\n",
    "            self.bot23 = nn.Conv1d(nhid, 4 * nhid, kernel_size=1)\n",
    "            self.bot24 = nn.Conv1d(4 * nhid, 16 * nhid, kernel_size=1)\n",
    "\n",
    "        self.uEnc11 = nn.Conv2d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "        self.uEnc12 = nn.Conv2d(nhid, nhid, kernel_size=ker, padding=1)\n",
    "\n",
    "        self.uEnc2 = self.convBlock(nhid, 2 * nhid, 2 * nhid, pool=True, pooling=4)\n",
    "        self.uEnc3 = self.convBlock(2 * nhid, 4 * nhid, 4 * nhid, pool=True, pooling=4)\n",
    "        self.uEnc4 = self.convBlock(4 * nhid, 8 * nhid, 8 * nhid, pool=True)\n",
    "        self.uEnc5 = self.convBlock(8 * nhid, 16 * nhid, 16 * nhid, pool=True)\n",
    "\n",
    "        if not self.unet:\n",
    "            self.dec5 = self.convBlock(32 * nhid, 8 * nhid, 8 * nhid, pool=False)\n",
    "        else:\n",
    "            self.dec5 = self.convBlock(16 * nhid, 8 * nhid, 8 * nhid, pool=False)\n",
    "\n",
    "        self.dec4 = self.convBlock(16 * nhid, 4 * nhid, 4 * nhid, pool=False)\n",
    "        self.dec3 = self.convBlock(8 * nhid, 2 * nhid, 2 * nhid, pool=False, pooling=4)\n",
    "        self.dec2 = self.convBlock(4 * nhid, nhid, nhid, pool=False, pooling=4)\n",
    "\n",
    "        self.dec11 = nn.Conv2d(2 * nhid, nhid, kernel_size=ker, padding=1)\n",
    "        self.dec12 = nn.Conv2d(nhid, inCh, kernel_size=ker, padding=1)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.mu_0 = torch.zeros((1, nlatent)).to(device)\n",
    "        self.sigma_0 = torch.ones((1, nlatent)).to(device)\n",
    "\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def vae_encoder(self, x):\n",
    "        x = self.act(self.enc11(x))\n",
    "        x = self.act(self.enc12(x))\n",
    "        x = self.enc2(x)\n",
    "        x = self.enc3(x)\n",
    "        x = self.enc4(x)\n",
    "        x = self.enc5(x)\n",
    "\n",
    "        z = self.act(self.bot11(x.view(x.shape[0], x.shape[1], -1)))\n",
    "        z = self.bot12(z.permute(0, 2, 1))\n",
    "\n",
    "        return z.squeeze(-1)\n",
    "\n",
    "    def unet_encoder(self, x_in):\n",
    "        x = []\n",
    "\n",
    "        x.append(self.act(self.uEnc12(self.act(self.uEnc11(x_in)))))\n",
    "        x.append(self.uEnc2(x[-1]))\n",
    "        x.append(self.uEnc3(x[-1]))\n",
    "        x.append(self.uEnc4(x[-1]))\n",
    "        x.append(self.uEnc5(x[-1]))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x_enc, z=None):\n",
    "        if not self.unet:\n",
    "            x = self.act(self.bot21(z.unsqueeze(2)))\n",
    "            x = self.act(self.bot22(x.permute(0, 2, 1)))\n",
    "            x = self.act(self.bot23(x))\n",
    "            x = self.act(self.bot24(x))\n",
    "\n",
    "            x = x.view(x.shape[0], x.shape[1],\n",
    "                       int(self.h / 64), int(self.w / 64))\n",
    "            x = torch.cat((x, x_enc[-1]), dim=1)\n",
    "            x = self.dec5(x)\n",
    "        else:\n",
    "            x = self.dec5(x_enc[-1])\n",
    "\n",
    "        x = torch.cat((x, x_enc[-2]), dim=1)\n",
    "        x = self.dec4(x)\n",
    "        x = torch.cat((x, x_enc[-3]), dim=1)\n",
    "        x = self.dec3(x)\n",
    "        x = torch.cat((x, x_enc[-4]), dim=1)\n",
    "        x = self.dec2(x)\n",
    "        x = torch.cat((x, x_enc[-5]), dim=1)\n",
    "\n",
    "        x = self.act(self.dec11(x))\n",
    "        x = self.dec12(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        kl = torch.zeros(1).to(device)\n",
    "        z = 0.\n",
    "        x_enc = self.unet_encoder(x)\n",
    "\n",
    "        if not self.unet:\n",
    "            emb = self.vae_encoder(x)\n",
    "            mu, log_var = torch.chunk(emb, 2, dim=1)\n",
    "            log_var = nn.functional.softplus(log_var)\n",
    "            sigma = torch.exp(log_var / 2)\n",
    "            posterior = distributions.Independent(\n",
    "                distributions.Normal(loc=mu, scale=sigma), 1)\n",
    "            z = posterior.rsample()\n",
    "            prior = distributions.Independent(\n",
    "                distributions.Normal(loc=self.mu_0, scale=self.sigma_0), 1)\n",
    "            kl = distributions.kl.kl_divergence(posterior, prior).sum()\n",
    "        xHat = self.decoder(x_enc, z)\n",
    "\n",
    "        return kl, xHat\n",
    "\n",
    "    class convBlock(nn.Module):\n",
    "        def __init__(self, inCh, nhid, nOp, pool=True, ker=3, padding=1, pooling=2):\n",
    "            super().__init__()\n",
    "            self.enc1 = nn.Conv2d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "            self.enc2 = nn.Conv2d(nhid, nOp, kernel_size=ker, padding=1)\n",
    "            self.bn = nn.BatchNorm2d(inCh)\n",
    "\n",
    "            if pool:\n",
    "                self.scale = nn.AvgPool2d(kernel_size=pooling)\n",
    "            else:\n",
    "                self.scale = nn.Upsample(scale_factor=pooling)\n",
    "            self.pool = pool\n",
    "            self.act = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.scale(x)\n",
    "            x = self.bn(x)\n",
    "            x = self.act(self.enc1(x))\n",
    "            x = self.act(self.enc2(x))\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largestCC(lImg, num=2):\n",
    "    cIdx = np.zeros(num, dtype=int)\n",
    "    count = np.bincount(lImg.flat)\n",
    "    count[0] = 0\n",
    "    lcc = np.zeros(lImg.shape, dtype=bool)\n",
    "    if len(count) == 2:\n",
    "        num = 1\n",
    "    for i in range(num):\n",
    "        cIdx[i] = np.argmax(count)\n",
    "        count[cIdx[i]] = 0\n",
    "        lcc += (lImg == cIdx[i])\n",
    "\n",
    "    return lcc\n",
    "\n",
    "\n",
    "def post_process(img, s=11):\n",
    "    bImg = (img > 0.5)\n",
    "    if len(bImg.shape) > 2:\n",
    "        bImg = bImg[:, :, -1]\n",
    "    sEl = morphology.disk(s)\n",
    "    lImg = measure.label(bImg)\n",
    "    lcc = largestCC(lImg)\n",
    "    pImg = morphology.binary_closing(lcc, sEl)\n",
    "    return pImg.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_img(img):\n",
    "    temp_width = 448\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "\n",
    "    temp_height = int((img.shape[0] / (img.shape[1] / temp_width)))\n",
    "    if temp_height > 576:\n",
    "        temp_height = 576\n",
    "        temp_width = int((img.shape[1] / (img.shape[0] / temp_height)))\n",
    "\n",
    "    img = transform.resize(img, (temp_height, temp_width))\n",
    "    img = exposure.equalize_hist(img)\n",
    "\n",
    "    img = torch.Tensor(img)\n",
    "    padded_img = torch.zeros((640, 512))\n",
    "    padding_h = (int((576 - temp_height) / 2)) + PADDING\n",
    "    padding_w = int((448 - temp_width) / 2) + PADDING\n",
    "    roi = torch.zeros(padded_img.shape)\n",
    "\n",
    "    if padding_w == PADDING:\n",
    "        padded_img[np.abs(padding_h):(padding_h + img.shape[0]), PADDING:-PADDING] = img\n",
    "        roi[np.abs(padding_h):(padding_h + img.shape[0]), PADDING:-PADDING] = 1.0\n",
    "    else:\n",
    "        padded_img[PADDING:-PADDING, np.abs(padding_w):(padding_w + img.shape[1])] = img\n",
    "        roi[PADDING:-PADDING, np.abs(padding_w):(padding_w + img.shape[1])] = 1.0\n",
    "\n",
    "    padded_img = padded_img.unsqueeze(0).unsqueeze(0)\n",
    "    return padded_img, roi, padding_h, padding_w, temp_height, temp_width, img_height, img_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba80c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_mask(padded_mask, padding_h, padding_w, temp_height, temp_width, img_height, img_width, apply_post_process=False):\n",
    "    padded_mask = padded_mask.data.numpy()\n",
    "\n",
    "    if apply_post_process:\n",
    "        padded_mask = post_process(padded_mask)\n",
    "\n",
    "    if padding_w == PADDING:\n",
    "        mask = padded_mask[np.abs(padding_h):(padding_h + temp_height), PADDING:-PADDING]\n",
    "        mask = transform.resize(image=mask,\n",
    "                      output_shape=(img_height, img_width),\n",
    "                      preserve_range=True)\n",
    "    else:\n",
    "        mask = padded_mask[PADDING:-PADDING, np.abs(padding_w):(padding_w + temp_width)]\n",
    "        mask = transform.resize(image=mask,\n",
    "                      output_shape=(img_height, img_width),\n",
    "                      preserve_range=True)\n",
    "\n",
    "    mask = img_as_ubyte(mask > 0.5)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a59f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(model, img):\n",
    "    padded_img, roi, p_h, p_w, temp_h, temp_w, original_h, original_w = pad_img(img)\n",
    "\n",
    "    padded_img = padded_img.to(device)\n",
    "    _, padded_mask = model(padded_img)\n",
    "    padded_mask = torch.sigmoid(padded_mask * roi)\n",
    "\n",
    "    mask = unpad_mask(padded_mask.squeeze(), p_h, p_w, temp_h, temp_w, original_h, original_w, POST_PROCESS)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = io.imread(path)\n",
    "    img = img / img.max()\n",
    "#     img = color.rgb2gray(img[:, :, :3])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2087",
   "metadata": {},
   "source": [
    "### Apply CLAHE and overlay mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e643ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask(img, mask, histogram_equalization=True):\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    result = cv2.bitwise_and(img, mask)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361da47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "\n",
    "def overlay_mask(img, mask):\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    cl1 = clahe.apply(img)    \n",
    "    result = cv2.bitwise_and(cl1, mask)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0a329",
   "metadata": {},
   "source": [
    "# Load model and segment images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a992620",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(f'{DATA_PATH}*')\n",
    "images = sorted(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img_path in enumerate(images):\n",
    "    img_name = img_path.split('/')[-1].split('.')[0]\n",
    "    pred_path = f'{PREDICTIONS_DIR}{img_name}_pred.png'\n",
    "    mask_path = f'{MASKS_DIR}{img_name}_mask.png'\n",
    "\n",
    "    img = load_img(img_path)\n",
    "\n",
    "    mask = get_mask(net, img)\n",
    "    pred = overlay_mask(img, mask)\n",
    "\n",
    "    io.imsave(pred_path, pred)\n",
    "    io.imsave(mask_path, mask)\n",
    "\n",
    "    print(f\"Segmenting {idx + 1}/{len(images)}: {img_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
